设备在显示字符的时候，会把不能显示的字符显示为符号�，即“\ufffd”。

是的，终端显示字符的时候，还有一个显示字符集，这里就不展开了。
“\ufffd”用UTF-8编码是多少呢，EFBFBD，用三个字节表示。UTF-8编码是可变长度的，
但是我们的GBK编码是定长，2个字节。当两个UTF-8编码的�，即EFBFBD EFBFBD，被当作GBK解码的时候。
就会解码成3个字符，EFBF BDEF BFBD，在GBK编码中这三个字符就是大名鼎鼎的“锟斤拷”.


nicode 虽然解决了 ASCII 码的兼容性问题，但是它又带来了新的问题。
ASCII 只需要 1 个字节就能解决英文世界的字符编码，而 Unicode 为了支持多语言，最多需求 4 个字节的编码空间。
也就是说，一篇纯英文文章以 Unicode 编码存储在计算机中所消耗的内存是要大于以 ASCII 编码进行存储的，这不就造成内存资源的浪费了吗？所以这就有了 UTF-8.

**Unicode定义了码值，utf-8以最少空间占用方式对Unicode进行了实现，即使用的非原始的码值的二进制传输，中间做了变换**

先简要介绍两个概念：unicode是将字符与码点（code point，一个整数）一一对应的编码方案；码点通常用uXXXX或者U+XXXX的方式表示，XXXX是码点的十六进制；

UTF-8（8-bit Unicode Transformation Format）是一种针对 Unicode 的可变长度实现方式。

接下来我们就来看一下 UTF-8 是如何解决 Unicode 的空间浪费问题。根据最新的规范，UTF-8 使用一至四个字节为每个字符编码，也就是说是可变长度的。
其编码中的第一个字节仍与 ASCII 兼容，这使得原来处理 ASCII 字符的软件无须或只须做少部分修改，就可以继续使用。

汉字“码” 为例，根据上表（表格来自于维基百科）进行转换。首先“码”的 Unicode 编码为 U+7801，
显然位于表中第三行的 U+0800 和 U+FFFF 之间。U+7801 对应的 16 进制编码为 7801，
将其转换为二进制 111 1000 0000 0001。
然后，我们把得到的二进制编码从右到左依次替换到 1110xxxx 10xxxxxx 10xxxxxx 里的 x 位置上，
不够的位置用 0 来补足。最终我们得到一串二进制数据 1110 0111 1010 0000 1000 0001，这串数据就是汉字“码”对应的 UTF-8 编码。


中文字符
中文属于多字节 Unicode 字符，之前我们讲过比如通过 Unicode 属性，但有一些语言是不支持这种属性的，
可以通过另外一个办法，就是 码值的范围，中文的范围是 4E00 - 9FFF 之间，这样可以覆盖日常使用大多数情况。

不同的语言是表示方式有一些差异，比如：
在 Python，Java，JavaScript 中
Unicode 可以写成 \u 码值 来表示，即匹配中文的正则可以写成 [\u4E00-\u9FFF]






