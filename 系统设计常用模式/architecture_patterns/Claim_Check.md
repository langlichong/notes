# Claim Check (提取码模式)

在消息传递系统中，为了解决 **“大尺寸传输有效载荷导致管道拥塞”** 的问题，将大的数据资产存入外部持久化存储，而仅通过消息队列发送一个“引用（引用凭据）”。

## 1. 痛点：被千万级大礼包压垮的小管道

消息中间件（Kafka, RabbitMQ, RocketMQ）的设计初衷是处理 **“海量小消息”**（1KB ~ 10KB）。

**灾难场景**：
1.  **大包进场**：由于业务需要。每条订单产生时，都要把用户的 pdf 合同（5MB）一并塞进消息里发给下游。
2.  **集群罢工**：
    *   **内存耗尽**：一个 Batch 如果包含 100 条这种消息，瞬间吃掉 500MB 内存，触发 GC 停顿。
    *   **吞吐骤降**：Kafka 的磁盘读写和顺序磁盘寻道会因为这种巨大 Packet 的搬运而陷入瓶颈。
    *   **成本爆炸**：Kafka 的副本同步流量暴涨 10 倍，云上的网络带宽费让你心疼。

**结论**：消息队列是发指令用的，不是用来搬运集装箱的。

---

## 2. 解决方案：托运与提取码

这个模式借鉴了超市的行李存放柜：

### 核心步骤
1.  **生产者 (寄存)**：在发消息前。发现是个大家伙。先把它存入 **S3/OSS/MinIO**。
2.  **获取凭证 (提取码)**：存储系统返回一个唯一的 `Key` 或下载 `URL`。
3.  **发送消息 (瘦身)**：往 Kafka 里的只定义 `{ "claim_check_id": "key-123" }`。这个消息只有几百个字节。
4.  **接收者 (凭票领取)**：下游消费者拿到 Key，主动调用 S3 的接口把大数据下载下来再处理。

---

## 3. 实现策略

### 自动处理逻辑
优秀的架构中，你可以写一个中间件拦截器：
*   **计算大小**：如果 `msg.size() > 1MB`。
*   **透明转换**：拦截器自动执行存储并重构消息体。
*   **反向转换**：消费者端的拦截器自动解析出 Key 并预先加载文件到内存，业务代码层完全无感知。

---

## 4. 注意事项与挑战

1.  **数据清理 (Cleanup)**：这是最容易忘的。什么时候删 S3 里的文件？建议设置 TTL 或者在最后一个消费者拉走后触发删除。
2.  **二次往返开销**：由于要额外调一次对象存储。对于延迟极其敏感的场景（毫秒级）需要慎重。
3.  **引用完整性**：如果消息还没被处理，S3 的文件不小心被删了。整个业务就断了。

---

## 5. 适用场景

*   **图片批量处理**：传图片的 key 而非 base64。
*   **报表导出**：导出完成后发一个消息告诉用户，消息里包含文件链接。
*   **法律合同签署流程**。

## 6. 总结
提取码模式是消息领域的 **“减负神器”**。
*   **信条**：只传指令。如果指令太重，请放行李寄存处。
*   **收益**：极大地提高了消息中间件的稳定性和吞吐上限。
