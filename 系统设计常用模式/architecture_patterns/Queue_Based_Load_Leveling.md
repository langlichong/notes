# Queue-Based Load Leveling (基于队列的削峰填谷模式)

通过在流量入口与处理端之间插入一个消息队列作为"缓冲区"，将不可预测的、脉冲式的流量洪峰转化为平稳、可控的恒定负载，从而保护后端系统免受瞬时过载的摧毁。

## 1. 痛点：脉冲式流量的"瞬间冲击"

在实际生产环境中，流量往往不是平稳的：

**极端场景**：
1.  **秒杀活动**：晚上 8 点整。10 万用户同时点击"立即购买"。
    *   如果这 10 万个请求直接打到数据库，DB 连接池（假设 200 个连接）瞬间爆满。
    *   剩下 99,800 个请求卡在那等待。
    *   数据库 CPU 飙到 100%，响应时间从 5ms 变成 30 秒。
    *   **结果**：所有请求都超时失败，系统彻底崩溃。
2.  **营销短信发送**：运营在后台点了一下"群发 100 万条短信"。
    *   短信网关每秒只能发 1000 条。
    *   如果同步调用，用户要等 1000 秒（16 分钟）才能看到"发送成功"。
3.  **数据导入**：用户上传一个 Excel，里面有 50 万行数据要入库。

**本质问题**：流量是"尖峰"，但处理能力是"恒定"的。直接硬扛会导致系统被瞬间击穿。

---

## 2. 解决方案：队列作为"减震器"

在前端和后端之间插入消息队列：

### 运行逻辑
```
[Client (100万请求/秒)] 
    --> [MQ Queue (无限容量)] 
        --> [Worker (恒定速度: 1000个/秒)]
```

1.  **快速接收**：所有请求立刻扔进 RabbitMQ 或 Kafka。接口瞬间返回 `202 Accepted（已接受，处理中）`。
2.  **平稳消费**：后端 Worker 以自己能承受的速度（每秒 1000 个）慢慢处理队列。
3.  **时间换空间**：用户可能需要等几分钟，但系统不会崩溃。

---

## 3. 实现策略

### 场景 A: 秒杀系统
```java
@PostMapping("/seckill")
public ResponseEntity<?> seckill(@RequestBody OrderRequest req) {
    // 1. 快速预校验（库存是否充足？用户是否已购买？）
    if (!inventoryService.quickCheck(req)) {
        return ResponseEntity.status(429).body("库存不足");
    }
    
    // 2. 放入队列，立即返回
    rabbitTemplate.convertAndSend("seckill-queue", req);
    
    return ResponseEntity.accepted().body("排队中，请稍候查询结果");
}

// Worker 消费者
@RabbitListener(queues = "seckill-queue")
public void processOrder(OrderRequest req) {
    // 真正的下单逻辑（扣库存、扣款、创建订单）
    orderService.createOrder(req);
}
```

### 场景 B: 批量任务处理
*   Excel 导入：解析每一行后放入队列。
*   Worker 以恒定速度（比如每秒 100 行）写入数据库。
*   前端通过轮询或 WebSocket 查询进度。

---

## 4. 关键优势

1.  **系统稳定性**：后端始终以最优负载运行，不会因突发流量崩溃。
2.  **用户体验**：虽然响应变成了异步，但总比"直接报错"或"卡死 30 秒"要好。
3.  **成本优化**：不需要为了应对 1 小时的秒杀流量，而长期维护 100 倍的服务器资源。

---

## 5. 注意事项与挑战

*   **队列积压监控**：如果队列长度持续增长（比如超过 100 万条），说明 Worker 处理速度跟不上。需要扩容 Worker 实例。
*   **消息丢失**：必须确保消息队列的持久化（RabbitMQ / Kafka 开启持久化）。
*   **顺序性丧失**：如果有多个 Worker 并发消费，消息的处理顺序无法保证（需要用单 Worker 或 Kafka 分区键）。

---

## 6. 与 Rate Limiting 的区别

*   **限流 (Rate Limiting)**：直接拒绝超出阈值的请求。返回 HTTP 429。
*   **削峰填谷 (Load Leveling)**：不拒绝请求，而是暂时存起来，慢慢处理。
*   **选择建议**：如果是恶意攻击，用限流。如果是正常业务高峰，用削峰。

## 7. 总结
Queue-Based Load Leveling 是架构师的 **"时间银行"**。
*   **信条**：我现在扛不住，但我可以分期付款。
*   **心法**：用异步化解同步的压力，用时间换取系统的生存空间。
