## Memory barrier
  - Memory Barrier是一种同步指令，是处理器或编译器用来强制对内存操作（如读、写）进行排序的机制。它的核心作用是确保在特定点之前的所有内存操作都已经完成，并且对其他处理器是可见的

  <img width="773" height="350" alt="image" src="https://github.com/user-attachments/assets/16a66f4e-d749-41da-9c9a-9f33546fd799" />
  <img width="776" height="517" alt="image" src="https://github.com/user-attachments/assets/cc2557ae-bceb-4f80-bc4f-6ed0c9d01b31" />

 ```text
   内存屏障是实现Java并发机制（如Happens-Before原则）的底层基石。
   它通过强制执行顺序和内存同步，解决了由编译器和处理器优化所带来的可见性和有序性问题，确保了多线程环境下程序的正确性。
 ```
  
- 阻塞锁
  ```text
  阻塞锁的工作原理
  阻塞锁的核心原理是“排他性”和“等待”。
  
  获取锁：一个线程尝试获取锁。如果锁当前没有被任何线程持有，该线程成功获取锁并继续执行。
  
  锁被占用：如果锁已经被其他线程持有，尝试获取锁的线程就会被阻塞。操作系统会将这个线程从CPU的运行队列中移除，使其进入休眠状态。这个过程被称为上下文切换（Context Switch）。
  
  释放锁：当持有锁的线程完成其任务后，它会释放锁。
  
  唤醒等待：释放锁的动作会通知JVM，JVM会从该锁的等待队列中唤醒一个或多个线程。被唤醒的线程会重新进入可运行状态，等待CPU调度，然后再次尝试获取锁。
  
  在Java中，最常见的阻塞锁就是synchronized关键字和java.util.concurrent.locks.Lock接口的实现类（如ReentrantLock）。

  阻塞锁的优缺点
    优点：
    
    避免CPU空转：线程被阻塞后，它不再占用CPU资源。CPU可以被分配给其他有用的线程，提高了CPU的利用率。
    
    适用于高竞争、长等待的场景：当线程等待锁的时间较长时，阻塞锁的效率很高。因为一次上下文切换的开销远小于长时间的CPU空转。
    
    缺点：
    
    上下文切换开销：上下文切换是一个重量级操作，涉及到保存和恢复线程的执行状态。如果锁的竞争非常激烈，或者线程等待的时间很短，频繁的上下文切换会导致性能下降。
    
    可能导致死锁：如果多个线程互相持有对方需要的锁，并且都在等待对方释放，就会发生死锁。
  ```
- 自旋锁(忙等待)
  ```text
  如果等待时间很短（通常是微秒或纳秒级别），自旋是更好的选择。
  因为上下文切换的开销（通常在几微秒到几十微秒）可能比自旋等待的时间还要长。
  volatile或Atomic自旋锁常用于轻量级、低竞争的场景，比如双重检查锁定、状态标志位等

  如果等待时间不确定，且可能很长（毫秒或秒级别），阻塞锁是更好的选择。
  自旋会持续占用CPU资源，导致CPU空转，造成不必要的浪费。在这种情况下，应该让线程阻塞，让出CPU给其他有用的任务执行
  ```
